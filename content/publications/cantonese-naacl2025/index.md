---
title: 'How Well Do LLMs Handle Cantonese? Benchmarking Cantonese Capabilities of Large Language Models'

authors:
  - Jiyue Jiang
  - Pengan Chen
  - Liheng Chen
  - me
  - Qinghang Bao
  - Lingpeng Kong
  - Yu Li
  - Chuan Wu

date: '2025-01-01'
publishDate: '2024-08-10'

publication_types: ['paper-conference']

publication: In *The 2025 Annual Conference of the Nations of the Americas Chapter of the ACL*
publication_short: In *NAACL 2025 Findings*

abstract: 'The rapid evolution of large language models (LLMs) has transformed the competitive landscape in natural language processing (NLP), particularly for English and other data-rich languages. However, underrepresented languages like Cantonese, spoken by over 85 million people, face significant development gaps. This paper introduces new benchmarks designed to evaluate LLM performance in factual generation, mathematical logic, complex reasoning, and general knowledge in Cantonese.'

summary: 'NAACL 2025 Findings paper benchmarking Cantonese capabilities of LLMs.'

tags:
  - Cantonese
  - LLM Evaluation
  - NAACL

featured: false

links:
  - type: preprint
    url: https://arxiv.org/abs/2408.16756

hugoblox:
  ids:
    arxiv: '2408.16756'
---
